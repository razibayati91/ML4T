{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6fd39a0",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this notebook we will consider a general approach to link prediction described in the paper \"[Link Prediction Based on Graph Neural Networks](https://www.researchgate.net/profile/Muhan-Zhang/publication/323443864_Link_Prediction_Based_on_Graph_Neural_Networks/links/5dc113364585151435e9382a/Link-Prediction-Based-on-Graph-Neural-Networks.pdf).\"\n",
    "\n",
    "\n",
    "The basic idea here is to extract a subgraph around a link to be detected, and then classify the subgraph. The nodes in these subgraphs can have a feature vector built from attributes or embeddings obtained via an encoder (or both). This effectively translates a link prediction problem into a graph prediction problem.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f970de3f",
   "metadata": {},
   "source": [
    "# Azure setup\n",
    "AML environemt setup and vaialbels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6afd3b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Environment, Experiment, ComputeTarget\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cf4ffd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME link-prediction-train\n",
      "COMPUTE_NAME devchamlc01\n",
      "MODEL_NAME GNN-link-prediction\n",
      "MODEL_VERSION 1\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT_NAME = os.environ.get(\"EXPERIMENT_NAME\", \"link-prediction-train\")\n",
    "#CONDA_PATH = os.environ.get(\"CONDA_PATH\", \"../.azureml/score.yml\")\n",
    "COMPUTE_NAME = os.environ.get(\"COMPUTE_NAME\", \"devchamlc01\") #mt\n",
    "MODEL_NAME = os.environ.get(\"MODEL_NAME\", \"GNN-link-prediction\")\n",
    "MODEL_VERSION = os.environ.get(\"MODEL_VERSION\", \"1\")\n",
    "\n",
    "\n",
    "print(\"EXPERIMENT_NAME {}\".format(EXPERIMENT_NAME))\n",
    "#print(\"CONDA_PATH {}\".format(CONDA_PATH))\n",
    "print(\"COMPUTE_NAME {}\".format(COMPUTE_NAME))\n",
    "print(\"MODEL_NAME {}\".format(MODEL_NAME))\n",
    "print(\"MODEL_VERSION {}\".format(MODEL_VERSION))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50c96da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found workspace mazcacdevchaml01 at location canadacentral\n"
     ]
    }
   ],
   "source": [
    "ws = Workspace.from_config()\n",
    "#ws = Workspace.get(name=\"mazcacnpeamlmtaml01\",\n",
    "#               subscription_id='046f49cd-89e9-495b-ae8d-a90fc8173ab3',\n",
    "#               resource_group='maz-cac-aml-wstn-mt-rg')\n",
    "\n",
    "print(\"Found workspace {} at location {}\".format(ws.name, ws.location))\n",
    "\n",
    "compute_target = ComputeTarget(ws, COMPUTE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c79d9d5",
   "metadata": {},
   "source": [
    "# package requirments\n",
    " install pytorch, go to https://pytorch.org/. It has instructions for how to install pytorch with cuda support."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c251833a",
   "metadata": {},
   "source": [
    "# pytorch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2606b46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
      "Requirement already satisfied: torch-scatter in /opt/anaconda3/lib/python3.8/site-packages (2.0.9)\n",
      "Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
      "Requirement already satisfied: torch-sparse in /opt/anaconda3/lib/python3.8/site-packages (0.6.12)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.8/site-packages (from torch-sparse) (1.6.2)\n",
      "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /opt/anaconda3/lib/python3.8/site-packages (from scipy->torch-sparse) (1.20.1)\n",
      "Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
      "Requirement already satisfied: torch-cluster in /opt/anaconda3/lib/python3.8/site-packages (1.5.9)\n",
      "Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
      "Requirement already satisfied: torch-spline-conv in /opt/anaconda3/lib/python3.8/site-packages (1.2.1)\n",
      "Requirement already satisfied: torch-geometric in /opt/anaconda3/lib/python3.8/site-packages (2.0.2)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.8/site-packages (from torch-geometric) (1.20.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.8/site-packages (from torch-geometric) (0.24.1)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.8/site-packages (from torch-geometric) (1.3.3)\n",
      "Requirement already satisfied: rdflib in /opt/anaconda3/lib/python3.8/site-packages (from torch-geometric) (6.0.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.8/site-packages (from torch-geometric) (2.11.3)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.8/site-packages (from torch-geometric) (2.5)\n",
      "Requirement already satisfied: pyparsing in /opt/anaconda3/lib/python3.8/site-packages (from torch-geometric) (2.4.7)\n",
      "Requirement already satisfied: PyYAML in /opt/anaconda3/lib/python3.8/site-packages (from torch-geometric) (5.4.1)\n",
      "Requirement already satisfied: yacs in /opt/anaconda3/lib/python3.8/site-packages (from torch-geometric) (0.1.8)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.8/site-packages (from torch-geometric) (2.25.1)\n",
      "Requirement already satisfied: googledrivedownloader in /opt/anaconda3/lib/python3.8/site-packages (from torch-geometric) (0.4)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.8/site-packages (from torch-geometric) (1.6.2)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.8/site-packages (from torch-geometric) (4.59.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/anaconda3/lib/python3.8/site-packages (from jinja2->torch-geometric) (1.1.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/anaconda3/lib/python3.8/site-packages (from networkx->torch-geometric) (5.0.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/anaconda3/lib/python3.8/site-packages (from pandas->torch-geometric) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/anaconda3/lib/python3.8/site-packages (from pandas->torch-geometric) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.8/site-packages (from rdflib->torch-geometric) (52.0.0.post20210125)\n",
      "Requirement already satisfied: isodate in /opt/anaconda3/lib/python3.8/site-packages (from rdflib->torch-geometric) (0.6.0)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from requests->torch-geometric) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/anaconda3/lib/python3.8/site-packages (from requests->torch-geometric) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.8/site-packages (from requests->torch-geometric) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda3/lib/python3.8/site-packages (from requests->torch-geometric) (1.26.7)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->torch-geometric) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->torch-geometric) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "# Please visit https://github.com/rusty1s/pytorch_geometric#pip-wheels for lastest installation instruction\n",
    "\n",
    "!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html -U\n",
    "!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html -U\n",
    "!pip install torch-cluster -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html -U\n",
    "!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html -U\n",
    "!pip install torch-geometric -U"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9d4a91",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61dfcbe0",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "dlopen(/opt/anaconda3/lib/python3.8/site-packages/torch_sparse/_convert_cpu.so, 6): Symbol not found: __ZN2at5emptyEN3c108ArrayRefIxEENS0_13TensorOptionsENS0_8optionalINS0_12MemoryFormatEEE\n  Referenced from: /opt/anaconda3/lib/python3.8/site-packages/torch_sparse/_convert_cpu.so\n  Expected in: /opt/anaconda3/lib/python3.8/site-packages/torch/lib/libtorch_cpu.dylib\n in /opt/anaconda3/lib/python3.8/site-packages/torch_sparse/_convert_cpu.so",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-35cc0e929dc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPPI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split_edges\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Load dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch_geometric/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_debug_enabled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_debug\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch_geometric/data/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mhetero_data\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHeteroData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtemporal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTemporalData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch_geometric/data/data.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m from typing import (Optional, Dict, Any, Union, List, Iterable, Tuple,\n\u001b[1;32m      2\u001b[0m                     NamedTuple, Callable)\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOptTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNodeType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEdgeType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeprecated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch_geometric/typing.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_sparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparseTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Types for accessing data ####################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch_sparse/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;34m'_relabel'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m ]:\n\u001b[0;32m---> 15\u001b[0;31m     torch.ops.load_library(importlib.machinery.PathFinder().find_spec(\n\u001b[0m\u001b[1;32m     16\u001b[0m         f'{library}_{suffix}', [osp.dirname(__file__)]).origin)\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/_ops.py\u001b[0m in \u001b[0;36mload_library\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0;31m# static (global) initialization code in order to register custom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0;31m# operators with the JIT.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloaded_libraries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/ctypes/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: dlopen(/opt/anaconda3/lib/python3.8/site-packages/torch_sparse/_convert_cpu.so, 6): Symbol not found: __ZN2at5emptyEN3c108ArrayRefIxEENS0_13TensorOptionsENS0_8optionalINS0_12MemoryFormatEEE\n  Referenced from: /opt/anaconda3/lib/python3.8/site-packages/torch_sparse/_convert_cpu.so\n  Expected in: /opt/anaconda3/lib/python3.8/site-packages/torch/lib/libtorch_cpu.dylib\n in /opt/anaconda3/lib/python3.8/site-packages/torch_sparse/_convert_cpu.so"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.datasets import PPI\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "\n",
    "# Load dataset \n",
    "PPI.url = \"https://data.dgl.ai/dataset/ppi.zip\" #  Workaround for wrong URL in pytorch geometric\n",
    "dataset_ppi = PPI(root=\"./tmp/ppi\") \n",
    "\n",
    "# For simplicity, pich the largest graph out of the dataset\n",
    "data = max(dataset_ppi, key= lambda x:x.num_nodes) \n",
    "\n",
    "# Remove properties related to node-labeling (not needed here)\n",
    "data.train_mask = data.val_mask = data.test_mask = data.y = None\n",
    "\n",
    "# Create train/val/test split\n",
    "data = train_test_split_edges(data, val_ratio=0.25, test_ratio=0.25,)\n",
    "#data.x = torch.ones([data.x.shape[0], 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6426af98",
   "metadata": {},
   "source": [
    "# SEAL algorithm\n",
    "The SEAL algorithm requires the extraction of subgraphs enclosing links, as well as the distance every node in the subgraph to each of the edge nodes. This functionality is not yet provided by Pytorch-Geometric, so we will using networkx for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3acb5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import to_networkx\n",
    "\n",
    "# Create a Data object using on only the positive training edges\n",
    "data_pos = Data(edge_index=data.train_pos_edge_index, num_nodes=data.num_nodes)\n",
    "\n",
    "# Convert this graph to networkx format\n",
    "G_train_pos=to_networkx(data_pos).to_undirected()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30d9bf8",
   "metadata": {},
   "source": [
    "In the SEAL link prediction framework, the nodes in the edge-enclosing subgraph are assigned a structural label according to their distance from the node-pair adjacent to the edge being considered. This label, called double radius, for node $i$ in the subgraph is defined by\n",
    "\n",
    "$$ f(i) = 1 + min(d_x,d_y) + (d/2)[(d/2)+(d\\%2)-1]$$\n",
    "where $x$ and $y$ are the nodes adjacent to the considered edge, $d_x$ is the distance of node $i$ to $x$, $d_y$ is the distance of node $i$ to $y$ and $d= d_x+d_y$.\n",
    "\n",
    "If $d_x = \\infty$ or $d_y = \\infty$ in the subgraph, they get a label of 0. The double radius of nodes $x$ and $y$ is 1. This helps identify the structural importance of nodes $x$ and $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423a4870",
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_radius(d_x, d_y):\n",
    "    if (d_x==0) or (d_y==0):\n",
    "        return 1\n",
    "    \n",
    "    if np.isinf(d_x) or np.isinf(d_y):\n",
    "        return 0\n",
    "    d = d_x + d_y\n",
    "    dr = 1 + min(d_x,d_y) + (d//2) * ( d//2 + d%2 -1 )\n",
    "    return dr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a537049",
   "metadata": {},
   "source": [
    "We need to obtain n-hop subgraphs around each node. We will use n_hop=1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776bf803",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ego_graphs(G, n_hops):\n",
    "    dict_ego_graphs= {}\n",
    "    for v in G.nodes():\n",
    "        dict_ego_graphs[v] = nx.ego_graph(G,v, n_hops)\n",
    "    return dict_ego_graphs\n",
    "  \n",
    "node_to_nhop_subgraphs = create_ego_graphs(G=G_train_pos,n_hops=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e924257",
   "metadata": {},
   "source": [
    "Once we have the n_hop subgraphs around each node, we can easily compute the double radius of the nodes in each edge-enclosing subgraph. (This is of course trivial for n_hop=1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbf4b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_edge_to_double_radii(node_to_nhop_subgraphs, edge, n_hops):\n",
    "    v_x, v_y = edge\n",
    "\n",
    "    # Compute distance from d_x to each node in subgraph\n",
    "    subgraph_x = node_to_nhop_subgraphs[v_x]\n",
    "    d_x = nx.single_source_shortest_path_length(subgraph_x, v_x, cutoff=n_hops)\n",
    "    \n",
    "    # Compute distance from d_y to each node in subgraph\n",
    "    subgraph_y = node_to_nhop_subgraphs[v_y]\n",
    "    d_y = nx.single_source_shortest_path_length(subgraph_y, v_y, cutoff=n_hops)\n",
    "    \n",
    "    # Get the union of the node ids for the two subgraphs\n",
    "    nodes_subgraph = set(d_x.keys()) | set(d_y.keys())\n",
    "\n",
    "    # Compute the double radius for each node in the union of the two subgraphs\n",
    "    double_radii = {}\n",
    "\n",
    "    for v_n in nodes_subgraph:\n",
    "        d_x_to_n = d_x.get(v_n, np.inf)\n",
    "        d_y_to_n = d_y.get(v_n, np.inf)\n",
    "        double_radii[v_n] = double_radius(d_x_to_n, d_y_to_n)\n",
    "    \n",
    "    return double_radii"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b9fd86",
   "metadata": {},
   "source": [
    "We will store the double radii for each edge-enclosing subgraph\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01d02e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to get the double radii\n",
    "def get_double_radii(edge_list, node_to_nhop_subgraph, n_hops):\n",
    "    edge_to_double_radii = {}\n",
    "\n",
    "    for edge in edge_list:\n",
    "        if edge[1]>edge[0]: # Only get enclosing subgraph once\n",
    "            double_radii=get_edge_to_double_radii(node_to_nhop_subgraphs,edge, n_hops=n_hops)\n",
    "            edge_to_double_radii[tuple(edge)] = double_radii\n",
    "    return edge_to_double_radii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310334a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_to_double_radii_train_pos = get_double_radii(data.train_pos_edge_index.T.numpy(), node_to_nhop_subgraphs, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f60d59",
   "metadata": {},
   "source": [
    "\n",
    "We will now build the same subgraphs for negative samples. For the sake of speed, we will only use one set of negative training edge samples. We will also have to create subgraphs for the validation and testing sets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a4a4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch_geometric.utils import negative_sampling\n",
    "neg_edge_index = negative_sampling(edge_index=data.train_pos_edge_index,\n",
    "                                    num_nodes=data.x.size(0))\n",
    "\n",
    "edge_to_double_radii_train_neg = get_double_radii(neg_edge_index.T.numpy(), node_to_nhop_subgraphs, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d6c81f",
   "metadata": {},
   "source": [
    "Compute the map from edge to enclosing-subgraph-nodes double radii for the validation and testing sets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b643c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_to_double_radii_val_pos = get_double_radii(data.val_pos_edge_index.T.numpy(), node_to_nhop_subgraphs, 1)\n",
    "\n",
    "edge_to_double_radii_val_neg = get_double_radii(data.val_neg_edge_index.T.numpy(), node_to_nhop_subgraphs, 1)\n",
    "\n",
    "edge_to_double_radii_test_pos = get_double_radii(data.test_pos_edge_index.T.numpy(), node_to_nhop_subgraphs, 1)\n",
    "\n",
    "edge_to_double_radii_test_neg = get_double_radii(data.test_neg_edge_index.T.numpy(), node_to_nhop_subgraphs, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcf5ffb",
   "metadata": {},
   "source": [
    "## Converting Networkx subgraphs back to Data Objects\n",
    "Let's recap what we have now. For each edge in the training set, we have extracted an enclosing subgraph. For each node we assigned a structural label called the \"double radius\". Now we need to translate each of these subgraphs to a list of PyG Data objects. We will also assign a feature vector made by concatenating a one-hot encoding of the double-radius to the original features in the dataset. We will record the existance or non-existance of an edge by assigning a label to these Data objects. (Note this may take some time to complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d142077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to create the dataset\n",
    "from torch_geometric.utils import subgraph\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tqdm import *\n",
    "\n",
    "def create_dataset(edge_to_double_radii_pos, edge_to_double_radii_neg, \n",
    "                   max_radius, edge_index, device):\n",
    "    # One-hot encoding to the maximum radius\n",
    "    X = [[i] for i in range(max_radius + 1)] \n",
    "    encoder = OneHotEncoder(sparse=False)\n",
    "    encoder.fit(X)\n",
    "\n",
    "    dataset = []\n",
    "\n",
    "    for graph_label, edge_to_double_radii in [(0, edge_to_double_radii_neg),\n",
    "                                        (1, edge_to_double_radii_pos)]:\n",
    "        for edge in tqdm(edge_to_double_radii):\n",
    "\n",
    "            double_radii_subgraph = edge_to_double_radii[edge] \n",
    "            node_ids_subgraph = sorted(double_radii_subgraph.keys())\n",
    "\n",
    "            # Create subgraph, with nodes relabed to be contiguous\n",
    "            edge_index_subgraph,_ = subgraph(node_ids_subgraph, edge_index,\n",
    "                                            relabel_nodes=True)\n",
    "\n",
    "            # Convert dict to np.array\n",
    "            double_radii_subgraph = np.asarray([double_radii_subgraph[key] \n",
    "                                                for key in node_ids_subgraph])\n",
    "\n",
    "            # Create one-hot encoding of the double-radii.\n",
    "            struct_features = encoder.transform(double_radii_subgraph.reshape(-1,1))\n",
    "\n",
    "            # Concatenate the one-hot encoding with the existing features of the graph\n",
    "            x= torch.cat([torch.tensor(struct_features,dtype=torch.float), \n",
    "                        data.x[node_ids_subgraph]],dim=1)\n",
    "\n",
    "            dataset.append(Data(x=x.to(device), edge_index=edge_index_subgraph.to(device), \n",
    "                            y=torch.tensor([graph_label]).to(device)).to(device))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfd3b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = create_dataset(edge_to_double_radii_train_pos, edge_to_double_radii_train_neg, 2, data_pos.edge_index, 'cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdad938a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d0338e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cc0cfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca3a54d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64c2a017",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "[1] David Liben-Nowell and Jon Kleinberg. The link-prediction problem for social networks. Journal of the\n",
    "American society for information science and technology, 58(7):1019–1031, 2007.\n",
    "\n",
    "[2] Lada A Adamic and Eytan Adar. Friends and neighbors on the web. Social networks, 25(3):211–230,\n",
    "2003.\n",
    "\n",
    "[3] Yehuda Koren, Robert Bell, and Chris Volinsky. Matrix factorization techniques for recommender systems.\n",
    "Computer, (8):30–37, 2009.\n",
    "\n",
    "[4] Maximilian Nickel, Kevin Murphy, Volker Tresp, and Evgeniy Gabrilovich. A review of relational machine\n",
    "learning for knowledge graphs. Proceedings of the IEEE, 104(1):11–33, 2016.\n",
    "\n",
    "[5] Tolutola Oyetunde, Muhan Zhang, Yixin Chen, Yinjie Tang, and Cynthia Lo. Boostgapfill: Improving\n",
    "the fidelity of metabolic network reconstructions through integrated constraint and pattern-based methods.\n",
    "Bioinformatics, 2016.\n",
    "\n",
    "[6] Joan Bruna, Wojciech Zaremba, Arthur Szlam, and Yann LeCun. Spectral networks and locally connected\n",
    "networks on graphs. arXiv preprint arXiv:1312.6203, 2013.\n",
    "\n",
    "[7] David K Duvenaud, Dougal Maclaurin, Jorge Iparraguirre, Rafael Bombarell, Timothy Hirzel, Alán\n",
    "Aspuru-Guzik, and Ryan P Adams. Convolutional networks on graphs for learning molecular fingerprints.\n",
    "In Advances in neural information processing systems, pages 2224–2232, 2015.\n",
    "\n",
    "[8] Thomas N Kipf and Max Welling. Semi-supervised classification with graph convolutional networks.\n",
    "arXiv preprint arXiv:1609.02907, 2016.\n",
    "\n",
    "[9] Mathias Niepert, Mohamed Ahmed, and Konstantin Kutzkov. Learning convolutional neural networks for\n",
    "graphs. In International conference on machine learning, pages 2014–2023, 2016.\n",
    "\n",
    "[10] Muhan Zhang, Zhicheng Cui, Marion Neumann, and Yixin Chen. An end-to-end deep learning architecture\n",
    "for graph classification. In AAAI, pages 4438–4445, 2018.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d698ab03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
