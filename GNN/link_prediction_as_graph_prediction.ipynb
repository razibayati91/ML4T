{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6fd39a0",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this notebook we will consider a general approach to link prediction described in the paper \"[Link Prediction Based on Graph Neural Networks](https://www.researchgate.net/profile/Muhan-Zhang/publication/323443864_Link_Prediction_Based_on_Graph_Neural_Networks/links/5dc113364585151435e9382a/Link-Prediction-Based-on-Graph-Neural-Networks.pdf).\"\n",
    "\n",
    "\n",
    "The basic idea here is to extract a subgraph around a link to be detected, and then classify the subgraph. The nodes in these subgraphs can have a feature vector built from attributes or embeddings obtained via an encoder (or both). This effectively translates a link prediction problem into a graph prediction problem.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f970de3f",
   "metadata": {},
   "source": [
    "# Azure setup\n",
    "AML environemt setup and vaialbels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6afd3b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Environment, Experiment, ComputeTarget\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3cf4ffd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME link-prediction-train\n",
      "COMPUTE_NAME devchamlc01\n",
      "MODEL_NAME GNN-link-prediction\n",
      "MODEL_VERSION 1\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT_NAME = os.environ.get(\"EXPERIMENT_NAME\", \"link-prediction-train\")\n",
    "#CONDA_PATH = os.environ.get(\"CONDA_PATH\", \"../.azureml/score.yml\")\n",
    "COMPUTE_NAME = os.environ.get(\"COMPUTE_NAME\", \"devchamlc01\") #mt\n",
    "MODEL_NAME = os.environ.get(\"MODEL_NAME\", \"GNN-link-prediction\")\n",
    "MODEL_VERSION = os.environ.get(\"MODEL_VERSION\", \"1\")\n",
    "\n",
    "\n",
    "print(\"EXPERIMENT_NAME {}\".format(EXPERIMENT_NAME))\n",
    "#print(\"CONDA_PATH {}\".format(CONDA_PATH))\n",
    "print(\"COMPUTE_NAME {}\".format(COMPUTE_NAME))\n",
    "print(\"MODEL_NAME {}\".format(MODEL_NAME))\n",
    "print(\"MODEL_VERSION {}\".format(MODEL_VERSION))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50c96da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found workspace mazcacdevchaml01 at location canadacentral\n"
     ]
    }
   ],
   "source": [
    "ws = Workspace.from_config()\n",
    "#ws = Workspace.get(name=\"mazcacnpeamlmtaml01\",\n",
    "#               subscription_id='046f49cd-89e9-495b-ae8d-a90fc8173ab3',\n",
    "#               resource_group='maz-cac-aml-wstn-mt-rg')\n",
    "\n",
    "print(\"Found workspace {} at location {}\".format(ws.name, ws.location))\n",
    "\n",
    "compute_target = ComputeTarget(ws, COMPUTE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c79d9d5",
   "metadata": {},
   "source": [
    "# package requirments\n",
    " install pytorch, go to https://pytorch.org/. It has instructions for how to install pytorch with cuda support."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c251833a",
   "metadata": {},
   "source": [
    "# pytorch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2606b46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
      "Requirement already satisfied: torch-scatter in /opt/anaconda3/lib/python3.8/site-packages (2.0.9)\n",
      "Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
      "Requirement already satisfied: torch-sparse in /opt/anaconda3/lib/python3.8/site-packages (0.6.12)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.8/site-packages (from torch-sparse) (1.6.2)\n",
      "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /opt/anaconda3/lib/python3.8/site-packages (from scipy->torch-sparse) (1.20.1)\n",
      "Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
      "Requirement already satisfied: torch-cluster in /opt/anaconda3/lib/python3.8/site-packages (1.5.9)\n",
      "Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
      "Requirement already satisfied: torch-spline-conv in /opt/anaconda3/lib/python3.8/site-packages (1.2.1)\n",
      "Requirement already satisfied: torch-geometric in /opt/anaconda3/lib/python3.8/site-packages (2.0.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.8/site-packages (from torch-geometric) (2.11.3)\n",
      "Requirement already satisfied: googledrivedownloader in /opt/anaconda3/lib/python3.8/site-packages (from torch-geometric) (0.4)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.8/site-packages (from torch-geometric) (1.3.3)\n",
      "Requirement already satisfied: PyYAML in /opt/anaconda3/lib/python3.8/site-packages (from torch-geometric) (5.4.1)\n",
      "Requirement already satisfied: yacs in /opt/anaconda3/lib/python3.8/site-packages (from torch-geometric) (0.1.8)\n",
      "Requirement already satisfied: pyparsing in /opt/anaconda3/lib/python3.8/site-packages (from torch-geometric) (2.4.7)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.8/site-packages (from torch-geometric) (1.20.1)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.8/site-packages (from torch-geometric) (1.6.2)\n",
      "Requirement already satisfied: rdflib in /opt/anaconda3/lib/python3.8/site-packages (from torch-geometric) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.8/site-packages (from torch-geometric) (2.25.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.8/site-packages (from torch-geometric) (0.24.1)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.8/site-packages (from torch-geometric) (4.59.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.8/site-packages (from torch-geometric) (2.5)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/anaconda3/lib/python3.8/site-packages (from jinja2->torch-geometric) (1.1.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/anaconda3/lib/python3.8/site-packages (from networkx->torch-geometric) (5.0.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/anaconda3/lib/python3.8/site-packages (from pandas->torch-geometric) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/anaconda3/lib/python3.8/site-packages (from pandas->torch-geometric) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n",
      "Requirement already satisfied: isodate in /opt/anaconda3/lib/python3.8/site-packages (from rdflib->torch-geometric) (0.6.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.8/site-packages (from rdflib->torch-geometric) (52.0.0.post20210125)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from requests->torch-geometric) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda3/lib/python3.8/site-packages (from requests->torch-geometric) (1.26.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/anaconda3/lib/python3.8/site-packages (from requests->torch-geometric) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.8/site-packages (from requests->torch-geometric) (2021.10.8)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->torch-geometric) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->torch-geometric) (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "# Please visit https://github.com/rusty1s/pytorch_geometric#pip-wheels for lastest installation instruction\n",
    "\n",
    "!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html -U\n",
    "!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html -U\n",
    "!pip install torch-cluster -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html -U\n",
    "!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html -U\n",
    "!pip install torch-geometric -U"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9d4a91",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61dfcbe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/torch_geometric/deprecation.py:13: UserWarning: 'train_test_split_edges' is deprecated, use 'transforms.RandomLinkSplit' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.datasets import PPI\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "\n",
    "# Load dataset \n",
    "PPI.url = \"https://data.dgl.ai/dataset/ppi.zip\" #  Workaround for wrong URL in pytorch geometric\n",
    "dataset_ppi = PPI(root=\"./tmp/ppi\") \n",
    "\n",
    "# For simplicity, pich the largest graph out of the dataset\n",
    "data = max(dataset_ppi, key= lambda x:x.num_nodes) \n",
    "\n",
    "# Remove properties related to node-labeling (not needed here)\n",
    "data.train_mask = data.val_mask = data.test_mask = data.y = None\n",
    "\n",
    "# Create train/val/test split\n",
    "data = train_test_split_edges(data, val_ratio=0.25, test_ratio=0.25,)\n",
    "#data.x = torch.ones([data.x.shape[0], 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6426af98",
   "metadata": {},
   "source": [
    "# SEAL algorithm\n",
    "The SEAL algorithm requires the extraction of subgraphs enclosing links, as well as the distance every node in the subgraph to each of the edge nodes. This functionality is not yet provided by Pytorch-Geometric, so we will using networkx for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3acb5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import to_networkx\n",
    "\n",
    "# Create a Data object using on only the positive training edges\n",
    "data_pos = Data(edge_index=data.train_pos_edge_index, num_nodes=data.num_nodes)\n",
    "\n",
    "# Convert this graph to networkx format\n",
    "G_train_pos=to_networkx(data_pos).to_undirected()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30d9bf8",
   "metadata": {},
   "source": [
    "In the SEAL link prediction framework, the nodes in the edge-enclosing subgraph are assigned a structural label according to their distance from the node-pair adjacent to the edge being considered. This label, called double radius, for node $i$ in the subgraph is defined by\n",
    "\n",
    "$$ f(i) = 1 + min(d_x,d_y) + (d/2)[(d/2)+(d\\%2)-1]$$\n",
    "where $x$ and $y$ are the nodes adjacent to the considered edge, $d_x$ is the distance of node $i$ to $x$, $d_y$ is the distance of node $i$ to $y$ and $d= d_x+d_y$.\n",
    "\n",
    "If $d_x = \\infty$ or $d_y = \\infty$ in the subgraph, they get a label of 0. The double radius of nodes $x$ and $y$ is 1. This helps identify the structural importance of nodes $x$ and $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "423a4870",
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_radius(d_x, d_y):\n",
    "    if (d_x==0) or (d_y==0):\n",
    "        return 1\n",
    "    \n",
    "    if np.isinf(d_x) or np.isinf(d_y):\n",
    "        return 0\n",
    "    d = d_x + d_y\n",
    "    dr = 1 + min(d_x,d_y) + (d//2) * ( d//2 + d%2 -1 )\n",
    "    return dr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a537049",
   "metadata": {},
   "source": [
    "We need to obtain n-hop subgraphs around each node. We will use n_hop=1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "776bf803",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ego_graphs(G, n_hops):\n",
    "    dict_ego_graphs= {}\n",
    "    for v in G.nodes():\n",
    "        dict_ego_graphs[v] = nx.ego_graph(G,v, n_hops)\n",
    "    return dict_ego_graphs\n",
    "  \n",
    "node_to_nhop_subgraphs = create_ego_graphs(G=G_train_pos,n_hops=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e924257",
   "metadata": {},
   "source": [
    "Once we have the n_hop subgraphs around each node, we can easily compute the double radius of the nodes in each edge-enclosing subgraph. (This is of course trivial for n_hop=1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1dbf4b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_edge_to_double_radii(node_to_nhop_subgraphs, edge, n_hops):\n",
    "    v_x, v_y = edge\n",
    "\n",
    "    # Compute distance from d_x to each node in subgraph\n",
    "    subgraph_x = node_to_nhop_subgraphs[v_x]\n",
    "    d_x = nx.single_source_shortest_path_length(subgraph_x, v_x, cutoff=n_hops)\n",
    "    \n",
    "    # Compute distance from d_y to each node in subgraph\n",
    "    subgraph_y = node_to_nhop_subgraphs[v_y]\n",
    "    d_y = nx.single_source_shortest_path_length(subgraph_y, v_y, cutoff=n_hops)\n",
    "    \n",
    "    # Get the union of the node ids for the two subgraphs\n",
    "    nodes_subgraph = set(d_x.keys()) | set(d_y.keys())\n",
    "\n",
    "    # Compute the double radius for each node in the union of the two subgraphs\n",
    "    double_radii = {}\n",
    "\n",
    "    for v_n in nodes_subgraph:\n",
    "        d_x_to_n = d_x.get(v_n, np.inf)\n",
    "        d_y_to_n = d_y.get(v_n, np.inf)\n",
    "        double_radii[v_n] = double_radius(d_x_to_n, d_y_to_n)\n",
    "    \n",
    "    return double_radii"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b9fd86",
   "metadata": {},
   "source": [
    "We will store the double radii for each edge-enclosing subgraph\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d01d02e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to get the double radii\n",
    "def get_double_radii(edge_list, node_to_nhop_subgraph, n_hops):\n",
    "    edge_to_double_radii = {}\n",
    "\n",
    "    for edge in edge_list:\n",
    "        if edge[1]>edge[0]: # Only get enclosing subgraph once\n",
    "            double_radii=get_edge_to_double_radii(node_to_nhop_subgraphs,edge, n_hops=n_hops)\n",
    "            edge_to_double_radii[tuple(edge)] = double_radii\n",
    "    return edge_to_double_radii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "310334a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_to_double_radii_train_pos = get_double_radii(data.train_pos_edge_index.T.numpy(), node_to_nhop_subgraphs, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f60d59",
   "metadata": {},
   "source": [
    "\n",
    "We will now build the same subgraphs for negative samples. For the sake of speed, we will only use one set of negative training edge samples. We will also have to create subgraphs for the validation and testing sets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1a4a4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch_geometric.utils import negative_sampling\n",
    "neg_edge_index = negative_sampling(edge_index=data.train_pos_edge_index,\n",
    "                                    num_nodes=data.x.size(0))\n",
    "\n",
    "edge_to_double_radii_train_neg = get_double_radii(neg_edge_index.T.numpy(), node_to_nhop_subgraphs, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d6c81f",
   "metadata": {},
   "source": [
    "Compute the map from edge to enclosing-subgraph-nodes double radii for the validation and testing sets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b643c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_to_double_radii_val_pos = get_double_radii(data.val_pos_edge_index.T.numpy(), node_to_nhop_subgraphs, 1)\n",
    "\n",
    "edge_to_double_radii_val_neg = get_double_radii(data.val_neg_edge_index.T.numpy(), node_to_nhop_subgraphs, 1)\n",
    "\n",
    "edge_to_double_radii_test_pos = get_double_radii(data.test_pos_edge_index.T.numpy(), node_to_nhop_subgraphs, 1)\n",
    "\n",
    "edge_to_double_radii_test_neg = get_double_radii(data.test_neg_edge_index.T.numpy(), node_to_nhop_subgraphs, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcf5ffb",
   "metadata": {},
   "source": [
    "## Converting Networkx subgraphs back to Data Objects\n",
    "Let's recap what we have now. For each edge in the training set, we have extracted an enclosing subgraph. For each node we assigned a structural label called the \"double radius\". Now we need to translate each of these subgraphs to a list of PyG Data objects. We will also assign a feature vector made by concatenating a one-hot encoding of the double-radius to the original features in the dataset. We will record the existance or non-existance of an edge by assigning a label to these Data objects. (Note this may take some time to complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d142077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to create the dataset\n",
    "from torch_geometric.utils import subgraph\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tqdm import *\n",
    "\n",
    "def create_dataset(edge_to_double_radii_pos, edge_to_double_radii_neg, \n",
    "                   max_radius, edge_index, device):\n",
    "    # One-hot encoding to the maximum radius\n",
    "    X = [[i] for i in range(max_radius + 1)] \n",
    "    encoder = OneHotEncoder(sparse=False)\n",
    "    encoder.fit(X)\n",
    "\n",
    "    dataset = []\n",
    "\n",
    "    for graph_label, edge_to_double_radii in [(0, edge_to_double_radii_neg),\n",
    "                                        (1, edge_to_double_radii_pos)]:\n",
    "        for edge in tqdm(edge_to_double_radii):\n",
    "\n",
    "            double_radii_subgraph = edge_to_double_radii[edge] \n",
    "            node_ids_subgraph = sorted(double_radii_subgraph.keys())\n",
    "\n",
    "            # Create subgraph, with nodes relabed to be contiguous\n",
    "            edge_index_subgraph,_ = subgraph(node_ids_subgraph, edge_index,\n",
    "                                            relabel_nodes=True)\n",
    "\n",
    "            # Convert dict to np.array\n",
    "            double_radii_subgraph = np.asarray([double_radii_subgraph[key] \n",
    "                                                for key in node_ids_subgraph])\n",
    "\n",
    "            # Create one-hot encoding of the double-radii.\n",
    "            struct_features = encoder.transform(double_radii_subgraph.reshape(-1,1))\n",
    "\n",
    "            # Concatenate the one-hot encoding with the existing features of the graph\n",
    "            x= torch.cat([torch.tensor(struct_features,dtype=torch.float), \n",
    "                        data.x[node_ids_subgraph]],dim=1)\n",
    "\n",
    "            dataset.append(Data(x=x.to(device), edge_index=edge_index_subgraph.to(device), \n",
    "                            y=torch.tensor([graph_label]).to(device)).to(device))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9bfd3b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26821/26821 [00:44<00:00, 601.55it/s]\n",
      "100%|██████████| 26689/26689 [00:54<00:00, 490.43it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = create_dataset(edge_to_double_radii_train_pos, edge_to_double_radii_train_neg, 2, data_pos.edge_index, 'cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6c4850",
   "metadata": {},
   "source": [
    "The dataset created in the previous cell is the training dataset. Create the validation and testing dataset using the same procedure. (You need the edge_to_double_radii dictionaries created in Exercise 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "81d0338e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13344/13344 [00:16<00:00, 829.42it/s]\n",
      "100%|██████████| 13344/13344 [00:21<00:00, 622.24it/s]\n",
      "100%|██████████| 13344/13344 [00:21<00:00, 620.32it/s]\n",
      "100%|██████████| 13344/13344 [00:26<00:00, 496.75it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_val = create_dataset(edge_to_double_radii_val_pos, edge_to_double_radii_val_neg, 2, data_pos.edge_index, 'cpu')\n",
    "\n",
    "dataset_test = create_dataset(edge_to_double_radii_test_pos, edge_to_double_radii_test_neg, 2, data_pos.edge_index, 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599234aa",
   "metadata": {},
   "source": [
    "\n",
    "# Handling multiple graphs in a batch\n",
    "We have created now a list of Data objects called dataset. Each Data object contains an edge_list, feature vector and label (check this!). We now need to create a GNN that assigns a label to each subgraph and we will be done with the link-prediction task.\n",
    "\n",
    "In Pytorch Geometric, multiple graphs can be treated as a single large graph when batching with a DataLoader object. Message passing between nodes is not affected, simply because nodes in different graphs will not be connected (PyG takes care of assigning appropriate node-labels during batching). In order to keep track of which graph a node belongs to, a Data object representing a batch has the .batch attribute when can be used to , for example, pool all the node features in a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0ca3a54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph labels of each node in the batch:  tensor([  0,   0,   0,  ..., 999, 999, 999])\n",
      "Number of nodes in a batch: 67367\n",
      "Number of edges in a batch: 470324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/torch_geometric/deprecation.py:13: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "loader = DataLoader(dataset=dataset,batch_size=1000,shuffle=True)\n",
    "\n",
    "# Example\n",
    "for data_batch in loader:\n",
    "  break\n",
    "print(\"Graph labels of each node in the batch: \", data_batch.batch)\n",
    "print(\"Number of nodes in a batch:\", data_batch.num_nodes)\n",
    "print(\"Number of edges in a batch:\", data_batch.num_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e53b700b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13344"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([1 for d in dataset_val if d.y == 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d698ab03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53510"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0590713c",
   "metadata": {},
   "source": [
    "\n",
    "# Graph Classification GNN\n",
    "We will now define a simple graph classification GNN. This basically consists of one convolutional layer, followed by global mean pooling, and finally a linear layer and log_softmax for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "77003665",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv, glob\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GraphClassifierNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(dataset[0].num_node_features, 4)\n",
    "        self.lin = torch.nn.Linear(4, 2)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = glob.global_mean_pool(x, batch)\n",
    "        x = self.lin(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f93f70",
   "metadata": {},
   "source": [
    "Train the graph network and compute the AUC of the validation and test set (Use results from Exercise 1 and Exercise 2). A sample training script is provided below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b7a5b6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, dataset):\n",
    "    model.eval()\n",
    "    loader = DataLoader(dataset=dataset,batch_size=1000,shuffle=False)\n",
    "    labels = []\n",
    "    predicted = []\n",
    "    for data in loader:\n",
    "        preds = torch.argmax(model(data.to('cpu')), dim=1)\n",
    "        labels.extend(data.y.cpu().numpy())\n",
    "        predicted.extend(preds.cpu().numpy())\n",
    "    return roc_auc_score(labels, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38e43c2",
   "metadata": {},
   "source": [
    "Here we train the model on the training set and show the train, validation and test AUC\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "185b4cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [00:26<01:46,  6.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 epoches......\n",
      "train auc: 0.7751996897166312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/torch_geometric/deprecation.py:13: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation auc: 0.7738309352517986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/torch_geometric/deprecation.py:13: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      " 25%|██▌       | 5/20 [00:45<02:48, 11.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test auc: 0.7788519184652278\n",
      "loss: 0.5021047592163086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [01:18<01:36,  8.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 epoches......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/torch_geometric/deprecation.py:13: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train auc: 0.7931347590442444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/torch_geometric/deprecation.py:13: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation auc: 0.7935776378896884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/torch_geometric/deprecation.py:13: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      " 50%|█████     | 10/20 [01:35<01:52, 11.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test auc: 0.7944019784172662\n",
      "loss: 0.4427393674850464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [02:09<00:54,  9.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 epoches......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/torch_geometric/deprecation.py:13: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train auc: 0.7950141831250815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/torch_geometric/deprecation.py:13: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation auc: 0.7963504196642686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/torch_geometric/deprecation.py:13: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      " 75%|███████▌  | 15/20 [02:26<00:57, 11.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test auc: 0.7959757194244603\n",
      "loss: 0.45655009150505066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [03:06<00:10, 10.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 epoches......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/torch_geometric/deprecation.py:13: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train auc: 0.7955463790444207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/torch_geometric/deprecation.py:13: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation auc: 0.7947766786570744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/torch_geometric/deprecation.py:13: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "100%|██████████| 20/20 [03:27<00:00, 10.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test auc: 0.7977368105515588\n",
      "loss: 0.4525902271270752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "graph_classifier= GraphClassifierNet().to(\"cpu\")\n",
    "optimizer = torch.optim.Adam(graph_classifier.parameters(), lr=0.01)\n",
    "graph_classifier.train()\n",
    "\n",
    "for epoch in tqdm(range(1, 21)):\n",
    "  for data in loader:\n",
    "    optimizer.zero_grad() \n",
    "    log_softmax = graph_classifier(data.to(\"cpu\")) \n",
    "    nll_loss = F.nll_loss(log_softmax, data.y.cpu())\n",
    "    nll_loss.backward()\n",
    "    optimizer.step()\n",
    "  if epoch % 5 == 0:\n",
    "    print(f'{epoch} epoches......')\n",
    "    print('train auc:', test(graph_classifier, dataset))\n",
    "    print('validation auc:', test(graph_classifier, dataset_val))\n",
    "    print('test auc:', test(graph_classifier, dataset_test))\n",
    "    print('loss:', nll_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932a4e91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
